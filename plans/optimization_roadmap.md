# Optimization Roadmap ‚Äî PeopleCounter app_v2
> Cr√©√© : 2026-02-18 | GPU : RTX 5060 Ti (Blackwell sm_120) | TRT : 10.15.1.29 | Cible : 4K@30FPS

---

## Contexte & baseline

### Clarifications architecturales
- **Format YOLO** : `images` ‚Üí NCHW FP32 (`[batch, 3, height, width]`). Ni kHWC ni kNV12 support√©s nativement. La conversion NV12‚ÜíRGB est obligatoire, mais fusionnable.
- **Engines actuels** : `yolo26n-seg-fp8-qdq.engine` (dynamic batch, FP8 Q/DQ), `yolo26n-seg-fp8-b32.engine` (batch32 FP8). Plus de variantes batch1/16/32 s√©par√©es ‚Äî profil dynamique.
- **Pipeline tiles** : 1 batch global (yolo_global) sur stream d√©di√© + 2 groupes parall√®les de ~16 tiles chacun (yolo_tiles, `YoloTilingParallelTRT`, 2 contexts TRT s√©par√©s).

### M√©triques baseline (38 tests, cam√©ra r√©elle, ASYNC_OVERLAY)
| M√©trique | Valeur | Budget | Statut |
|---|---|---|---|
| `end_to_end_ms` | **37.6 ms** | 33 ms | üî¥ +14% |
| `fusion_wait_ms` | **20.1 ms** | 8 ms | üî¥ +250% |
| `inference_model_yolo_tiles_ms` | 19.9 ms | 20 ms | üü¢ 99% |
| `inference_model_yolo_global_ms` | 3.6 ms | 15 ms | üü¢ |
| `preprocess_nv12_bridge_ms` | 8.7 ms | 16 ms | üü¢ |
| `nvdec_ms` | 1.3 ms | 42 ms | üü¢ |
| Tests passants | **42 / 42** | ‚Äî | ‚úÖ |

### Fichier de suivi des gains
‚Üí [optimization_gains.html](optimization_gains.html) (g√©n√©r√© automatiquement apr√®s chaque √©tape)

---

## Plan d'optimisation

### #1 ‚Äî Timing Cache persistant ‚úÖ PRIORIT√â IMM√âDIATE
**Effort** : ~1h | **Impact** : builds d√©terministes, rebuild 5-10√ó plus rapide

**Probl√®me** : `convert_onnx_to_trt.py` et `prepare_yolo_modelopt_fp8.py` ne persistent pas le timing cache TRT. Les tactics peuvent varier entre rebuilds sur sm_120 (FP8 Q/DQ).

**Impl√©mentation** :
- Modifier `convert_onnx_to_trt.py` : charger/sauvegarder `models/tensorrt/timing_cache.bin`
- Modifier `prepare_yolo_modelopt_fp8.py` : idem
- Ajouter classe `TimingCacheManager` dans `app_v2/infrastructure/`
- Tests : `test_timing_cache_manager.py` ‚Äî v√©rifier que le cache est cr√©√© et recharg√©

**R√©f√©rence TRT** : `sampleEditableTimingCache`, `demo/BERT/builder.py`

---

### #2 ‚Äî CUDA Graphs pour l'inf√©rence r√©p√©titive
**Effort** : 2-3j | **Impact estim√©** : ‚àí2 √† ‚àí5 ms sur `enqueue_ms` tiles

**Probl√®me** : `execute_async_v3()` re-soumet √† chaque frame le graphe complet de kernels CUDA ‚Üí overhead CPU non n√©gligeable sur tiles b=16 √† 30 FPS.

**Principe** : capturer le graphe une fois au warmup, puis `cudaGraphLaunch()` √† chaque frame (quasi-z√©ro overhead CPU).

**Contraintes** :
- N√©cessite des shapes fixes (incompatible avec dynamic batch en capture mode) ‚Üí on capture sur `opt_batch_size`
- La TRT execution context doit supporter un mode "graph_captured"
- Pas compatible avec re-shape mid-run ‚Üí fallback sur `execute_async_v3` si batch ‚â† captured

**Impl√©mentation** :
- Ajouter `CudaGraphCache` dans `app_v2/infrastructure/`
- √âtendre `TensorRTExecutionContext` avec option `enable_cuda_graphs: bool`
- Tests : `test_cuda_graph_execution.py` ‚Äî v√©rifier graph capture + launch + r√©sultats identiques

**R√©f√©rence TRT** : utilis√© dans les d√©mos Diffusion TRT, cuda-python APIs

---

### #3 ‚Äî AutoCast FP32‚ÜíFP16 mixte (ModelOpt AutoCast)
**Effort** : ~1j | **Impact** : alternative sans calibration, potentiellement meilleur que full-FP8 sur tiles

**Principe** : `modelopt.onnx.autocast.convert_to_mixed_precision()` identifie automatiquement les n≈ìuds sensibles (normalization, activations) et les garde en FP32, le reste en FP16. Pas besoin d'images de calibration.

**Int√©r√™t** : comparaison A/B FP8-QDQ vs FP16-mixte sur les tiles 640√ó640. Le FP16-mixte peut √™tre plus rapide si les Q/DQ nodes introduisent de l'overhead.

**Impl√©mentation** :
- Nouveau script `prepare_yolo_autocast_fp16.py` (similaire √† `prepare_yolo_modelopt_fp8.py`)
- Output : `models/tensorrt/yolo26n-seg-autocast-fp16.engine`
- Tests : `test_autocast_fp16_engine.py` ‚Äî v√©rifier que l'engine charge et produit des r√©sultats coh√©rents

**R√©f√©rence TRT** : `samples/python/strongly_type_autocast/`

---

### #4 ‚Äî Weight Stripping + Engine Refit
**Effort** : ~1j | **Impact** : engine disque ‚àí60% taille, refit √† chaud possible (A/B models)

**Principe** : engine "stripped" sans les poids ‚Üí d√©ploiement all√©g√©. Au d√©marrage, refit depuis le fichier `.onnx` original via `IParserRefitter` (~30 ms). Performances identiques.

**Int√©r√™t additionnel** : pouvoir swapper les poids sans rebuild complet de l'engine (ex: switch yolo26n ‚Üî yolo26m sans rebuild TRT).

**Impl√©mentation** :
- Modifier `convert_onnx_to_trt.py` : ajouter option `--weight-stripped`
- Cr√©er `TensorRTEngineRefitter` dans `app_v2/infrastructure/`
- Int√©grer dans `TensorRTEngineLoader.load()` : detect stripped engine ‚Üí refit auto
- Tests : `test_engine_refit.py` ‚Äî v√©rifier refit + inf√©rence coh√©rente

**R√©f√©rence TRT** : `samples/python/sample_weight_stripping/`

---

### #5 ‚Äî Kernel fusionn√© NV12‚ÜíRGB+Resize+NCHW *(le plus gros gain potentiel)*
**Effort** : 3-5j | **Impact estim√©** : **‚àí4 √† ‚àí8 ms** sur `preprocess_nv12_bridge_ms` (8.7 ms ‚Üí ~1-2 ms)

**Probl√®me actuel** :
1. `nv12_cuda_bridge.py` ‚Üí NV12 √† GPU ptr ‚Üí RGB HWC uint8 tensor (8.7 ms) 
2. `preprocess.py` ‚Üí letterbox/tiling ‚Üí NCHW FP16 tensor (0.005 ms, d√©j√† rapide)

Le goulot est l'√©tape 1. Un kernel fusionn√© ferait en **un seul pass** : NV12 plane ptr ‚Üí letterbox/tile ‚Üí NCHW FP16 normalis√© [0,1]. Z√©ro tensor interm√©diaire.

**Format YOLO confirm√©** : `images` NCHW FP32 (dtype=1). L'execution context castait en FP16 √† la vol√©e ‚Üí le kernel peut sortir directement en FP16.

**D√©pendances Docker** :
- `cuda-python` (d√©j√† pr√©sent depuis TRT 10.14 migration)
- Triton (`triton` package) ou compilation C extension PyTorch ‚Üí √† tester dans image
- Alternative pure PyTorch : `torch.ops.torchvision` ou custom kernel via `torch.utils.cpp_extension`

**Impl√©mentation** :
- √âcrire `app_v2/kernels/fused_nv12_preprocess.py` avec kernel Triton ou cuda-python
- Fallback sur `nv12_cuda_bridge` si kernel indisponible (d√©gradation gracieuse)
- Tests : `test_fused_nv12_preprocess.py` ‚Äî comparer output avec pipeline existant (MSE < Œµ)

---

### #6 ‚Äî IStreamWriter (s√©rialisation engine ‚Üí m√©moire/r√©seau)
**Effort** : ~0.5j | **Impact** : d√©ploiement sans I/O disque, chargement engine depuis RAM

**Principe** : `builder.build_serialized_network_to_stream()` + classe `IStreamWriter` custom ‚Üí s√©rialiser directement vers un buffer m√©moire ou un socket. Utile pour Docker sans volume `models/`.

**Impl√©mentation** :
- Cr√©er `app_v2/infrastructure/engine_stream_serializer.py`
- Modifier `TensorRTEngineLoader` pour accepter `bytes` en plus de path

**R√©f√©rence TRT** : `samples/python/stream_writer/`

---

## Ordre d'ex√©cution recommand√©

```
#1 Timing Cache     ‚Üí builds d√©terministes (pr√©requis pour comparer les suivants)
#3 AutoCast FP16    ‚Üí comparaison A/B vs FP8, sans risque
#4 Weight Stripping ‚Üí infrastructure propre pour la suite
#2 CUDA Graphs      ‚Üí optimisation runtime inference
#5 Kernel fusionn√©  ‚Üí plus gros impact, plus risqu√©, en dernier
#6 IStreamWriter    ‚Üí infrastructure, peut se faire en parall√®le
```

---

## Tableau de suivi des gains

> Les m√©triques `end_to_end_ms` / `inference_tiles_ms` / `bridge_ms` n√©cessitent une cam√©ra r√©elle (NVDEC_TEST_STREAM_URL).

| # | Optimisation | Fichiers cr√©√©s / modifi√©s | Tests | `end_to_end_ms` | `inference_tiles_ms` | `bridge_ms` | Statut |
|---|---|---|---|---|---|---|---|
| 0 | **Baseline** | ‚Äî | 42 ‚úÖ | 37.6 ms üî¥ | 19.9 ms | 8.7 ms | ‚úÖ r√©f√©rence |
| 1 | **Timing Cache** | `timing_cache_manager.py`, `convert_onnx_to_trt.py`, `prepare_yolo_modelopt_fp8.py` | +14 ‚Üí 56 ‚úÖ | *(infra, pas d'impact latence)* | *(infra)* | ‚Äî | ‚úÖ mesur√© |
| 2 | **CUDA Graphs** | `cuda_graph_cache.py`, `tensorrt_execution_context.py` | +8 ‚Üí 64 ‚úÖ | √† mesurer (cam√©ra requise) | √† mesurer | ‚Äî | ‚úÖ impl√©ment√© |
| 3 | **AutoCast FP16** | `prepare_yolo_autocast_fp16.py`, `2_prepare_nvdec.sh` | +7 ‚Üí 71 ‚úÖ | √† mesurer | ‚àí2.4 % GPU tiles | ‚Äî | ‚úÖ mesur√© trtexec |
| 4 | **Weight Stripping** | `engine_refitter.py`, `convert_onnx_to_trt.py` | +11 ‚Üí 82 ‚úÖ | *(perf = FP32)* | *(perf = FP32)* | ‚Äî | ‚úÖ mesur√© trtexec |
| 5 | **Fused NV12+letterbox** | `nv12_cuda_bridge.py`, `preprocess.py` | +7 ‚Üí 89 ‚úÖ | √† mesurer | √† mesurer | üéØ ‚àí4 ms vis√© | ‚úÖ impl√©ment√© |
| 6 | **IStreamWriter** | `engine_stream_writer.py` ‚Üí `stream_writers/` | +12 ‚Üí 101 ‚úÖ | *(infra)* | *(infra)* | ‚Äî | ‚úÖ impl√©ment√© |

**Total tests** : 42 (baseline) ‚Üí **101** (+59 nouveaux tests)

---

## Benchmarks moteur ‚Äî GPU Compute median (RTX 5060 Ti sm_120, 2026-02-18)

> Commande : `trtexec --loadEngine=<engine> --shapes=images:Bx3x640x640 --warmUp=200 --iterations=100 --avgRuns=10`
> Valeurs = GPU Compute Time median (hors H2D/D2H). Latency totale ‚âà GPU + 1.55 ms (H2D) + 1.37 ms (D2H).

### yolo26n-seg (7.8 MB FP32) ‚Äî tiles parall√®les

| Format | Taille | batch=1 | batch=8 | batch=16 | batch=32 | Recommandation |
|--------|--------|---------|---------|----------|----------|----------------|
| **FP32** (baseline) | 7.8 MB | 2.63 ms | 5.21 ms | 9.38 ms | 18.59 ms | r√©f√©rence |
| **FP16** (opt #3) | 7.9 MB | 3.26 ms ‚ö†Ô∏è | **4.98 ms** | **9.08 ms** | 18.93 ms | batch‚â•8 seulement |
| **FP8-QDQ** | 6.5 MB | 2.66 ms | 5.01 ms | **8.66 ms** | **17.71 ms** | ‚úÖ batch‚â•16 |
| **Stripped** (opt #4) | **4.1 MB** | =FP32 | =FP32 | =FP32 | =FP32 | d√©ploiement all√©g√© |

‚ö†Ô∏è FP16 est **plus lent** que FP32 √† batch=1 sur yolo26n (mod√®le trop petit pour amortir les casts).

### yolo26m-seg (48 MB FP32) ‚Äî tile globale (batch=1) + plus grand mod√®le

| Format | Taille | batch=1 | batch=8 | batch=16 | batch=32 | Recommandation |
|--------|--------|---------|---------|----------|----------|----------------|
| **FP32** (baseline) | 48 MB | 5.53 ms | 22.71 ms | 45.85 ms | 92.87 ms | r√©f√©rence |
| **FP16** (opt #3) | ~30 MB | **5.24 ms** | 22.35 ms | 46.26 ms | 94.15 ms | batch=1 uniquement |
| **FP8-QDQ** | 30 MB | 5.05 ms | **19.75 ms** | **39.34 ms** | **80.98 ms** | ‚úÖ **tous batch** |

FP8-QDQ donne ‚àí13 % GPU compute sur yolo26m √† batch‚â•8. Tr√®s significatif pour ce mod√®le.

### Analyse architecture global tile + sous-tiles

L'id√©e : utiliser **yolo26m-seg FP8-QDQ (batch=1, ~5 ms)** pour la tile globale, et **yolo26n-seg FP8-QDQ (batch‚â§16, ~8.7 ms)** pour les sous-tiles en parall√®le.

```
Stream A (tile globale) :   yolo26m-seg FP8-QDQ  ‚Üí  5.05 ms GPU
Stream B (sous-tiles √óN) :  yolo26n-seg FP8-QDQ  ‚Üí  8.66 ms GPU (batch=16)
                                                      ‚Üë budget 33 ms ‚Äì 5 ms (transfer) = 28 ms = confortable
```

Les deux chemins tournent en parall√®le. La fusion (opt #2 √† venir) doit ensuite attendre le plus lent des deux ‚Äî avec ces chiffres le chemin sous-tiles est le goulot (~12 ms total avec transfers).

Pour ~16 tiles simultan√©es (batch=16) vs 1 frame globale :
- yolo26m FP8 batch=1 = 5 ms ‚Üê terminerait bien avant le batch de tiles
- yolo26n FP8 batch=16 = 8.66 ms ‚Üê goulot
- **√âquilibre** : on pourrait grouper jusqu'√† 16 tiles en un seul batch et le global tile finit ~3.6 ms avant ‚Üí tr√®s bon overlap

---

---

## Commandes de r√©f√©rence

```bash
# Tests complets (baseline)
./5_run_tests.sh --app-version v2

# Ou directement dans Docker
./docker_exec.sh python -m pytest app_v2/tests/ -v

# Rapport e2e avec cam√©ra (si NVDEC_TEST_STREAM_URL d√©fini)
NVDEC_TEST_STREAM_URL=rtsp://... ./docker_exec.sh python -m pytest \
  app_v2/tests/integration/pipeline/test_pipeline_metrics_integration.py \
  -v -s

# trtexec benchmark engine actuel
./docker_exec.sh trtexec \
  --loadEngine=models/tensorrt/yolo26n-seg-fp8-qdq.engine \
  --batch=16 --warmUp=500 --iterations=100 --avgRuns=10
```
