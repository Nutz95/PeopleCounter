# YOLO Performance Optimization Guide

Ce guide explique comment optimiser les performances d'infÃ©rence YOLO dans app_v2.

## ğŸ“Š Ã‰tat actuel des performances

**Baseline (FP16, yolo26n-seg.engine, split OFF)**
- `yolo_global`: ~6.3ms âœ…
- `yolo_tiles`: ~33ms ğŸ”´ (dÃ©passe budget 20ms)
- `end_to_end`: ~63ms ğŸ”´ (dÃ©passe cible 33ms pour 4K@30FPS)

**Avec split tiles x2 (split ON, 2 groupes)**
- `yolo_global`: ~9.4ms âœ…
- `yolo_tiles`: ~23ms ğŸŸ¡ (gain 30%, mais encore au-dessus budget)
- `end_to_end`: ~49ms ğŸŸ¡ (gain 22%)

## ğŸ¯ Optimisations disponibles

### Option 1: Quantization INT8 (RECOMMANDÃ‰ - Gain attendu: 2-4Ã—)

La quantization INT8 utilise les Tensor Cores INT8 du RTX 5060 Ti pour accÃ©lÃ©rer massivement l'infÃ©rence.

#### Ã‰tape 1: PrÃ©parer les images de calibration

Le script peut tÃ©lÃ©charger automatiquement un subset COCO:

```bash
./3b_prepare_int8_engines.sh yolo26n-seg 500 yes
```

OU si tu as dÃ©jÃ  des images de calibration:

```bash
# Placer 500-1000 images dans ./coco_val_subset/
./3b_prepare_int8_engines.sh yolo26n-seg 500 no
```

â±ï¸ **DurÃ©e**: 10-30 minutes selon taille dataset de calibration

#### Ã‰tape 2: Activer l'engine INT8

Ã‰diter `app_v2/config/pipeline.yaml`:

```yaml
models:
  yolo_global:
    enabled: true
    engine: models/tensorrt/yolo26n-seg-int8.engine  # â† ChangÃ©
  yolo_tiles:
    enabled: true
    engine: models/tensorrt/yolo26n-seg-int8.engine  # â† ChangÃ©
```

#### Ã‰tape 3: Tester les performances

```bash
./5_run_tests.sh --app-version v2 -k test_pipeline_e2e_real_stream_includes_inference_timings
```

Consulter le rapport HTML gÃ©nÃ©rÃ©: `app_v2/tests/integration/pipeline/artifacts/pipeline_e2e_metrics.html`

**Gain attendu**: `yolo_tiles` devrait passer de ~23ms Ã  ~6-12ms (objectif <= 10ms atteignable!)

---

### Option 2: Split tiles parallÃ¨le (Gain mesurÃ©: 30%)

âš ï¸ **ATTENTION**: Cette optimisation prÃ©sente des limites de scaling!

#### Comportement observÃ© (non-linÃ©aire!)

| Groupes | yolo_tiles | RÃ©sultat |
|---------|------------|----------|
| 1 (OFF) | ~33ms | Baseline |
| 2 | ~22ms | âœ… Gain 30% |
| 4 | ~28ms | âŒ DÃ‰GRADATION |
| 8 | ~54ms | âŒâŒ PIRE que baseline |

**Cause**: Python GIL + contention GPU + fragmentation batch size

#### Configuration

Ã‰diter `app_v2/config/pipeline.yaml`:

```yaml
yolo_tiles_parallel:
  enabled: true   # â† Activer le split
  groups: 2       # âš ï¸ NE PAS dÃ©passer 2-3!
```

**Recommandation**: Rester Ã  **2 groupes maximum**. Plus de groupes = dÃ©gradation garantie.

---

### Option 3: CUDA Stream Async Natif (Futur)

Remplacer `ThreadPoolExecutor` par pattern CUDA pur pour Ã©liminer overhead Python GIL.

**Status**: ImplÃ©mentation prototype disponible dans `yolo_tiling_parallel_cuda_trt.py`

**Blocage actuel**: NÃ©cessite modification `TensorRTExecutionContext.execute()` pour mode non-blocking.

---

## ğŸ”¬ Comprendre les limitations du split parallÃ¨le

### Pourquoi Ã§a ne scale pas linÃ©airement?

**1. Python GIL (Global Interpreter Lock)**
- Les threads Python ne s'exÃ©cutent PAS vraiment en parallÃ¨le
- Le GIL force une exÃ©cution sÃ©quentielle avec overhead de context switching
- Overhead croÃ®t linÃ©airement avec le nombre de threads

**2. Fragmentation du batch size**
- 32 tiles / 2 groupes = 16 tiles/batch â†’ encore efficace âœ…
- 32 tiles / 4 groupes = 8 tiles/batch â†’ perte efficacitÃ© batch ğŸŸ¡
- 32 tiles / 8 groupes = 4 tiles/batch â†’ gaspillage total ğŸ”´
- **TensorRT pÃ©nalise** les petits batches (overhead kernel launch)

**3. Contention GPU**
- Trop de CUDA streams concurrents = compÃ©tition pour les SMs
- Saturation memory bandwidth
- Context switching overhead TRT

**4. Overhead crÃ©ation contextes TRT**
- Chaque groupe = 1 contexte TRT sÃ©parÃ©
- Plus de contextes = fragmentation mÃ©moire GPU
- Warnings TRT = symptÃ´me de gestion sub-optimale

### Pourquoi yolo_global ralentit aussi?

C'est la **preuve** que le problÃ¨me est systÃ¨me:
- Contention sur ressources GPU partagÃ©es
- Fragmentation mÃ©moire affecte TOUS les modÃ¨les
- Overhead de gestion des multiples contextes TRT

---

## ğŸ¯ StratÃ©gie recommandÃ©e

### Phase 1: INT8 Quantization (IMMÃ‰DIAT)

âœ… **Actions**:
1. ExÃ©cuter `./3b_prepare_int8_engines.sh yolo26n-seg`
2. Mettre Ã  jour `pipeline.yaml` avec engine INT8
3. Valider gain avec tests e2e
4. **Si objectif atteint** (tiles <= 10ms): STOP ici âœ…

### Phase 2: Split tiles x2 (SI NÃ‰CESSAIRE)

âš ï¸ **Seulement SI** INT8 seul ne suffit pas:
1. Activer `yolo_tiles_parallel.enabled: true`
2. Garder `groups: 2` (ne pas augmenter!)
3. Mesurer gain additionnel

### Phase 3: CUDA Async (FUTUR)

ğŸ”® **Si besoin ultime de perf**:
1. Refactorer `TensorRTExecutionContext` pour mode async
2. ImplÃ©menter pattern CUDA stream pur
3. Ã‰liminer ThreadPoolExecutor

---

## ğŸ“ Notes importantes

### Calibration INT8

- **Images nÃ©cessaires**: 500-1000 suffisent (subset COCO val2017)
- **Temps calibration**: ~10-30 minutes
- **Accuracy**: Perte < 1% en gÃ©nÃ©ral pour YOLO
- **Cache**: La calibration est sauvegardÃ©e (pas besoin de refaire)

### Warnings TRT

Les warnings `createInferRuntime differs` sont **bÃ©nins** mais indiquent:
- Architecture sub-optimale (multiples runtimes)
- Solution future: partager un seul runtime TRT global

### Tiling adaptatif

âŒ **NON RECOMMANDÃ‰** pour l'instant:
- ComplexitÃ© importante
- ROI incertain
- Prioriser INT8 + split x2 d'abord

---

## ğŸ§ª Validation des performances

### Tests ciblÃ©s

```bash
# Test e2e complet avec mÃ©triques dÃ©taillÃ©es
./5_run_tests.sh --app-version v2 -k test_pipeline_e2e_real_stream_includes_inference_timings

# Consulter rapport HTML
firefox app_v2/tests/integration/pipeline/artifacts/pipeline_e2e_metrics.html
```

### MÃ©triques Ã  surveiller

- `inference_model_yolo_tiles_ms`: objectif **<= 10ms**
- `end_to_end_ms`: objectif **<= 33ms** (4K@30FPS)
- `inference_prepare_batch_ms`: overhead prÃ©paration batch
- `inference_enqueue_ms`: overhead enqueue TRT
- `inference_stream_sync_ms`: temps synchronisation
- `inference_decode_ms`: dÃ©codage post-inference

---

## ğŸ“š RÃ©fÃ©rences

- **Migration plan**: [plans/app_v2_migration_plan.md](plans/app_v2_migration_plan.md)
- **Session notes**: `/memories/session/plan.md`
- **TensorRT INT8 docs**: https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#working-with-int8
- **Ultralytics export**: https://docs.ultralytics.com/modes/export/
